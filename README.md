
# üçï Kafka Order Simulation (Python ‚Ä¢ Docker ‚Ä¢ KRaft)

Ce projet est une **simulation simple d‚Äôun syst√®me de commande de livraison**, inspir√© de plateformes comme UberEats..  


Le projet repose sur :
- un **Producer Kafka** qui simule un client envoyant une commande
- un **Consumer Kafka** qui lit cette commande et l‚Äôaffiche
- un **Kafka local ex√©cut√© avec Docker**, en **mode KRaft**




## Objectifs :

Ce projet a pour but de comprendre concr√®tement :

- ce qu‚Äôest un **topic Kafka**
- comment fonctionne un **producer**
- comment fonctionne un **consumer**
- comment Kafka transporte des messages (bytes)
- la s√©rialisation JSON
- la lecture par **partition** et **offset**
- l‚Äôex√©cution de Kafka avec Docker en **mode KRaft**



## Vue globale du fonctionnement :

Flux de donn√©es :

```

producer.py  ‚Üí  Kafka (topic: orders)  ‚Üí  consumer.py

```

1. Le producer cr√©e une commande
2. La commande est convertie en JSON
3. Le message est envoy√© dans Kafka (topic `orders`)
4. Le consumer lit le message depuis Kafka
5. Le consumer affiche le contenu de la commande



## Structure du projet :

```

.
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ producer.py
‚îú‚îÄ‚îÄ consumer.py
‚îî‚îÄ‚îÄ README.md

```



## Kafka avec Docker üê≥ :

Kafka est lanc√© via **Docker Compose**, sans Zookeeper.  
Kafka fonctionne en **mode KRaft**, ce qui signifie que le broker Kafka g√®re lui-m√™me la coordination du cluster.

Kafka est accessible sur :

```

localhost:9092

````

C‚Äôest cette adresse qui est utilis√©e par le producer et le consumer.

### Configuration Kafka (extrait du `docker-compose.yml`)

```yaml
services:
  kafka:
    image: confluentinc/cp-kafka:7.8.3
    ports:
      - "9092:9092"
    environment:
      KAFKA_KRAFT_MODE: "true"
      KAFKA_PROCESS_ROLES: "broker,controller"
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka:9093"
      KAFKA_LISTENERS: "PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://localhost:9092"
````

### Explication

* **KAFKA_KRAFT_MODE** : active Kafka sans Zookeeper
* **broker,controller** : Kafka joue les deux r√¥les
* **9092** : port utilis√© par les clients (producer / consumer)



## Producer ‚Äî Envoi d‚Äôune commande (`producer.py`) :

Le producer simule un **client** qui passe une commande.

### Connexion √† Kafka

```python
producer_config = {
    "bootstrap.servers": "localhost:9092",
}

producer = Producer(producer_config)
```

Le producer se connecte au broker Kafka expos√© par Docker.



### Cr√©ation de la commande

```python
order = {
    "order_id": str(uuid.uuid4()),
    "user": "SKOURI Youssef",
    "item": "Pizza Pepperoni",
    "quantity": 1,
}
```

Cette commande est un simple dictionnaire Python contenant :

* un identifiant unique (`order_id`)
* l‚Äôutilisateur
* le produit command√©
* la quantit√©



### S√©rialisation de la commande

Kafka transporte des **bytes**, pas des objets Python.
La commande est donc convertie en JSON, puis encod√©e.

```python
value = json.dumps(order).encode("utf-8")
```



### Envoi du message dans Kafka

```python
producer.produce(
    topic="orders",
    value=value,
    callback=delivery_report
)
```

* le message est envoy√© dans le topic **`orders`**
* un callback est utilis√© pour confirmer la livraison



### Callback de livraison

```python
def delivery_report(err, msg):
    if err is not None:
        print(f"Delivery failed for record: {err}")
    else:
        print(
            f"Delivered to {msg.topic()} [{msg.partition()}] "
            f"@ offset {msg.offset()}: {msg.value().decode('utf-8')}"
        )
```

Ce callback affiche :

* le topic
* la partition
* l‚Äôoffset
* le contenu du message


### Flush final :

```python
producer.flush()
```

Le `flush()` force l‚Äôenvoi de tous les messages avant la fin du programme.



## Consumer ‚Äî Lecture des commandes (`consumer.py`) :

Le consumer simule un **service de suivi des commandes**.


### Configuration du consumer :

```python
conf = {
    "bootstrap.servers": "localhost:9092",
    "group.id": "order_tracker_debug",
    "enable.auto.commit": False,
}
```

* `group.id` identifie le groupe de consommateurs
* le commit automatique des offsets est d√©sactiv√©



### Assignation manuelle (partition + offset) :

```python
c.assign([TopicPartition("orders", 0, 50)])
```

Cela signifie que le consumer :

* lit le topic **orders**
* uniquement la partition **0**
* √† partir de l‚Äôoffset **50** (J'ai s√©lectionn√© 50 juste pour ne pas affich√© l'historique compl√®te)

Cette approche permet un contr√¥le pr√©cis de la position de lecture.



### Boucle de consommation :

```python
msg = c.poll(1.0)
```

* attend jusqu‚Äô√† 1 seconde un message
* retourne `None` si aucun message n‚Äôest disponible



### D√©codage et parsing JSON :

```python
raw = msg.value().decode("utf-8")
order = json.loads(raw)
```

Le message Kafka est :

1. d√©cod√© depuis les bytes
2. transform√© en dictionnaire Python



### Affichage de la commande :

```python
print(
    f"üçî Received order: {order['quantity']} x {order['item']} "
    f"from user {order['user']}"
)
```

Le consumer affiche une version lisible de la commande re√ßue.



### Fermeture propre :

```python
finally:
    c.close()
```

Le consumer est ferm√© correctement, m√™me en cas d‚Äôarr√™t du programme.



## Ex√©cution du projet :

### 1. D√©marrer Kafka :

```bash
docker-compose up -d
```

### 2. Lancer le consumer :

```bash
python consumer.py
```

### 3. Lancer le producer :

```bash
python producer.py
```

La commande envoy√©e par le producer appara√Æt imm√©diatement dans le terminal du consumer.
